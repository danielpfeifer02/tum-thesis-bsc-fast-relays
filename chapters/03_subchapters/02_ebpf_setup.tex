\section{eBPF Setup}\label{sec:ebpf_setup}
\subsection{Different BPF Programs}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=7cm]{figures/03_fast_relays/ebpf-setup.drawio.pdf}
    \caption[Types of eBPF programs at relay]{The relay has to be equipped with three BPF programs.}\label{fig:ebpf-programs}
\end{figure}

In order to allow the relay to forward packets independently of the userspace, we
need to equip the relay with three BPF programs as seen in figure.
Those three programs are 
\begin{itemize}
    \item a program that handles incoming traffic \textbf{from} the clients (client ingress),
    \item a program that handles outgoing traffic \textbf{to} the clients (client egress) and
    \item a program that handles incoming traffic \textbf{from} the video server (server ingress).
\end{itemize}
Their responsibilities then are
\begin{itemize}
    \item handling the initial registration of new clients and storing their information such as
    MAC addresses in a BPF map,
    \item intercepting the packets from the video server, duplicating and redirecting them to 
    the egress program (as well as sending one unaltered packet to userspace for state
    management purposes),
    \item receiving the redirected packets at egress, altering them using the client specific
    data, deciding (based on packet priority and client congestion) if a packets should be dropped 
    or sent, storing info on sent out packets for future congestion control purposes and finally sending 
    them out to the clients.
\end{itemize}
This setup allows us to separate any state management and congestion control from the actual
packet forwarding and thus makes leaving out any immediate userspace processing possible.

Following is a more detailed description of the responsibilities of each of the three programs.
\subsubsection{Client Ingress} 
The ingress eBPF program initially does some simple packet inspection on every incoming packet 
looking if the packet uses the correct protocols and addresses the right application layer.
This is done by initially parsing the Ethernet, IP and UDP headers, if present, and checking if 
the port matches the listening port the relay application is listening on.
This means the correct port is to be defined prior such that the eBPF program can associate 
a single or (multiple) relay instance(s) with the correct port.
In our case then, since we use QUIC, the program will check for QUIC long header packets that 
setup an initial connection and saves the transmitted state information such as connection id, 
stream related states, etc.~in an eBPF map together with information that is not directly known
by the userspace such as the MAC address of the client.
Saving data like the MAC address directly once the connection is set up allows to omit any further 
Address Resolution Protocol (ARP) steps later on. 
\subsubsection{Server Ingress}
Another ingress related program, this time for packets coming from the video server, is needed
to handle packet duplication and forwarding.
This program will receive the actual video packets from the server and then, based on an internal 
counter of how many clients actually want to receive the video, duplicate the packet accordingly.
The counter of clients will be updated by the userspace once a new connection is fully established
and the client is ready to receive the actual video data.
This might potentially cause some miniscule delay when updating the counter but sending cached 
video data to the client for a brief moment when updating the counter could be a solution for that. % TODO: needed?
Figure~\ref{fig:packet-forwarding-duplication} shows the packet duplication and forwarding process 
high level for an example setting with three clients that want to receive the video data.
In the ingress program from the server we need to consider a few things to ensure the correctness
of our approach.
These are:
\begin{enumerate}
    \item   The program can \textbf{only} forward packets that containing video data and must not 
            forward any other packets that contain e.g.~control data.
    \begin{enumerate}
        \item   This is fairly easy to achieve by doing some header inspection of the QUIC header
                which contains the packet type. Also since payload is generally sent using 
                0-RTT- (i.e.~short-) headers there is no need to consider long-header packets.
    \end{enumerate}

    \item   The program should pass an unaltered copy up to userspace to allow the QUIC library to
            gain knowledge of the packet and handle any state changes accordingly.
    \begin{enumerate}
        \item   Generally speaking this is not strictly necessary as one could just have a separate 
                setup of registering packets that came from the server but as this is not needed
                it is considerably easier to just pass the packet up to userspace and let the 
                library handle it normally. This does not impose any additional overhead as the
                forwarding of any duplicate packets happens independently of course.
        \item   Any packet that has been identified as not part of our dataflow should of course 
                be passed up to userspace without being forwarded to egress.
    \end{enumerate}
\end{enumerate}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/03_fast_relays/packet-forwarding.drawio.pdf}
    \caption[Video packet duplication]{Duplication and forwarding of video packets to egress directly 
    from ingress.}\label{fig:packet-forwarding-duplication}
\end{figure}

Duplicating and forwarding incoming packets happens using that were identified as payload 
can be done using \verb|bpf_clone_redirect(skb, egress_ifindex, 0)| which is a helper function
that allows one to clone the packet buffer provided as the first argument and add it to the 
queue of the interface that is provided as the second argument.
The last argument allows to specify additional flags.
Aside from \verb|bpf_clone_redirect| there are also other helper functions regarding packet
redirection with slightly different behavior so it is crucial to choose the appropriate one
to get the desired outcome.
Table~\ref{tab:skb-redirection} shows them together with a brief description of their behavior:

\begin{table}[htbp]
    \centering
    \begin{tabular}{L{7cm}L{7cm}}
        \toprule
            Helper & Description \\
        \midrule
            \verb|bpf_clone_redirect| & Clones and redirects a packet to the interface associated with the provided index.\\
        \midrule
            \verb|bpf_redirect| & Redirects a packet to the interface associated with the provided index. The packet is not cloned 
                                    (no underlying call of \verb|skb_clone()|) so it is slightly more efficient (25\% pps increase according 
                                    to commit message). The packet is also not redirected immediately but after the function finishes.\\ % TODO: find commit message
        \midrule
            \verb|bpf_redirect_peer| & Similar to \verb|bpf_redirect| but instead of redirecting the packet to the interface provided 
                                        as a parameter it is redirected to its peer device. This works only between different netns to 
                                        allow for an efficient ``ingress to ingress netns switch''. The switch is more performant since 
                                        the packet does not need to go through the CPU backlog queue.\\ % TODO: what does the CPU backlog queue do?
        \midrule
            \verb|bpf_redirect_neigh| & Again similar to \verb|bpf_redirect| but allows to redirect a packet to another net device. 
                                        This helper does also fill in all the correct L2 addresses of the neighboring subsystem. 
                                        Internally this executes a neighbor lookup to find the needed L2 information. \\
        \bottomrule
    \end{tabular}
    \caption[skb redirection helpers]{Helper functions for packet redirection.}\label{tab:skb-redirection}
\end{table}
% TODO: ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
% TODO: cite this: https://man7.org/linux/man-pages/man7/bpf-helpers.7.html
% TODO: cite this: http://arthurchiao.art/blog/differentiate-bpf-redirects/ ???
Based on the descriptions of the redirection helper functions mentioned in table~\ref{tab:skb-redirection}
it becomes clear that \verb|bpf_clone_redirect| is the only suitable for our use case. 
This is becaus we need the cloning aspect since we essentially want to duplicate the incoming packets multiple times.
Also the redirection to another namespace or another net device as provided by \verb|bpf_redirect_peer| and
\verb|bpf_redirect_neigh| respectively is not needed in our case since we operate in the same relay-namespace
throughout the whole process.

\subsubsection{Client Egress}
The client egress program sees every packet that leaves the relay. 
This includes packets that have been redirected by the ingress program as well as packets that
have been generated by the relay itself.
Since the QUIC protocol works with packet numbers for a given connection it is necessary for 
the egress program to make sure the forwarded packets together with the userspace packets
provide a consistent state. 
For this the egress program maintains its own packet number counter for each connection.
That way only one counter has to be maintained and race conditions can be avoided.
However, this also means that the packets sent by the userspace are likely to have a different 
packet number than the one chosen by the QUIC library.
This might lead to inconsistencies again but can be avoided by not storing a packet from userspace
right away in the packet history but only once the BPF has stored it, along with the changed
packet number, in the map used for packet registration. % TODO: check if this is true / implemented
This initially gives a brief window where a packet was sent out but is not saved in the history
of the QUIC library but once the packet is then processed by the userspace routine handling the 
registration, any incoming ACKs for this packet can be processed correctly.
% TODO: retransmission? maybe use relay cache for that?
TODO

\subsection{Packet Registration}
In order to make the congestion control algorithm that is running in userspace
usable we need to inform the QUIC library about the forwarded packets.
This again happens via BPF maps and a separate go routine that continuously
polls new entries in the map and processes them.
Entries are then added to the packet history to allow the receipt of ACKs.
Besides that, the congestion control algorithm will be informed about the
forwarded packet in order to be able to react to potential congestion events.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/03_fast_relays/forward-registration.drawio.pdf}
    \caption[Packet registration schematic]{Internal setup for registering forwarded packets as well as incorporating forwarding
    limitations for the BPF program.}\label{fig:forward-registration}
\end{figure}



TODO:~mention
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/03_fast_relays/stream-id-translation.drawio.pdf}
    \caption[Stream id translation schematic]{TODO (also mention that the check for previous translation is needed since >1 packets per unistream are possible)}\label{fig:stream-id-translation}
\end{figure}