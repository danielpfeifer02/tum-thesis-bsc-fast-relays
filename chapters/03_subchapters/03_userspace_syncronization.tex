\section{Userspace Synchronization}\label{sec:userspace_synchronization}

Since one of the main ideas we propose is to avoid passing a packet all the way
through the network stack up to userspace at the relay, we create the problem
that the application itself is not aware of packets that are being sent.
To conquer this issue, we suggest a setup that establishes communication
between the application- and the eBPF program.
To keep the improvement we gained by not passing packets to userspace during the 
critical path, this communication will happen in a delayed fashion, that is 
decoupled from the actual sending of media data.

The main resource we use for this communication will again be eBPF maps that
will contain information on the time a packet was sent together with protocol-specific 
data like packet-numbers or stream-identifiers (for both packet-number 
and stream-id the old and the new, i.e.~tranlsated, values will be stored).


% \subsection{User Space Avoidance}
% TODO 

\subsection{Subscription and State Management}
As already mentioned in~\autoref{sec:ebpf_setup}, an eBPF program handling incoming
traffic from the client will save client connection information like MAC address, IP 
address, et cetera, in a map for later access.
Also, an internal counter will give each client a unique identifier. % TODO: mention somewhere that this identifier has to be sequential and therefore does not support "unsubscribing" yet
With that, the only thing that happens in terms of communication between the application 
and the relay in case of a new subscription is that the application will update the ``number 
of clients'' counter that is accessed by the eBPF program and used for packet duplication purposes.

Regarding stream state management, there is also little additional communication since the 
server is expected to use QUIC's unidirectional streams for sending the media data. 
That means the relay does not need to know about the stream details except if it 
has to trigger a retransmission.
% TODO: already mentioned
% If that is the case, the stream-id contained in the packet (meta-)data, that was read from the eBPF map, 
% will be used to manually create a stream with the correct id.
% It is important to manually set the correct id since the relay might not use the same id for the 
% next unidirectional stream it opens.
% Also, the client expects the retransmission to be sent on the same stream-id as the original packet
% since a retransmission happens within the same stream-context.

Since a client can also unsubscribe from a certain media stream, the relay needs to support
this as well.
This is done by simply decrementing the ``number of clients'' counter and making sure the 
client ids stay in a usable state (i.e.~the relay is not duplicating packets for unsubscribed 
clients).
Our prototype implementation does not consider this yet, because our proof of concept and 
performance tests do not require it.

\subsection{Relay Caching}
Caching of data within a relay, which is required by the MoQ standard, is something we essentially get
for free since we are passing on an unaltered copy of any incoming packet from the server to the 
application at the same time we forward all the other packet copies to egress.
This means the application is able to receive any data from the server as if this was a normal connection and 
store, e.g.~the last \verb|n| second(s) worth of data in a cache.
Then the relay could, once a new connection is established, parallel to incrementing the kernel counter 
representing the number of clients also send out cached data already so that the client receives it
as early as possible.

One aspect that we still left open is the point in time when the relay should stop 
sending cached data since the forwarded data is up-to-date.
This also includes the question of how the client can handle potentially duplicate media data if the 
cached- and the forwarded data happen to overlap.
Such questions would likely require further experimenting and testing to find a good solution.
